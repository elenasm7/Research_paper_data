{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building and Training\n",
    "\n",
    "In this notebook we will train our model on mixed data through multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import bz2\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import concatenate\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(file_name,obj):\n",
    "    with open(file_name, 'wb') as fout:\n",
    "        pickle.dump(obj, fout)\n",
    "\n",
    "def open_pickle(file_name):\n",
    "    with open(file_name, 'rb') as handle:\n",
    "        obj = pickle.load(handle)\n",
    "    return obj\n",
    "\n",
    "def get_np_array_from_tar_object(tar_extractfl):\n",
    "    '''converts a buffer from a tar file in np.array'''\n",
    "    return np.asarray(bytearray(tar_extractfl.read())\n",
    "                      , dtype=np.uint8)\n",
    "\n",
    "\n",
    "def load_sky_images(df,yr=None,tar=None):\n",
    "    # initialize our images array (i.e., the house images themselves)\n",
    "    images = []\n",
    "    \n",
    "    yr = '0'\n",
    "    for img in df.values:\n",
    "        yr_file = img[:4]\n",
    "        if yr == yr_file:\n",
    "            pass\n",
    "        else:\n",
    "            if tar:\n",
    "                print(\"deleted tar\")\n",
    "                del tar\n",
    "        \n",
    "            yr = img[:4]\n",
    "            file = f'data/Folsom_sky_images_{yr}.tar.bz2'\n",
    "            print(yr,file)\n",
    "            tar = tarfile.open(file)\n",
    "        \n",
    "        image = cv2.imdecode(get_np_array_from_tar_object(tar.extractfile(img)), 0)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "        images.append(image)\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_dict = open_pickle('../data_rp/model_data_dict.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next 3 cells open the images from the tar.bz2 files using the `load_sky_images()` function. This will be a numpy array of all of the images for each instance in the df. We aren't using the built in stream from directory function of keras due to the file type. The files are very large, so I would prefer not to unzip them on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_5_min = model_data_dict['df_5_min']['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_img_5 = img_5_min.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014 data/Folsom_sky_images_2014.tar.bz2\n",
      "deleted tar\n",
      "2015 data/Folsom_sky_images_2015.tar.bz2\n",
      "deleted tar\n",
      "2016 data/Folsom_sky_images_2016.tar.bz2\n"
     ]
    }
   ],
   "source": [
    "images_5_min = load_sky_images(sorted_img_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_pickle('../data_rp/5_min_w_img.pkl',images_5_min)\n",
    "# images_5_min.shape\n",
    "images_5_min = open_pickle('../data_rp/5_min_w_img.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process our image data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model:\n",
    "\n",
    "The three parts of this section will be making adjustments to pre-trained CNN models, building an MLP, and then adding layers at the end to contatinate the results of these two branches of NN models, and then added fully connected and regression layers at the end.\n",
    "\n",
    "So, let's break them out: \n",
    "1. [Update pre-trained CNN models for image data](#Update-pretrained-CNN-models)\n",
    "2. [Build MLP for numeric/categorical data](#Build-MLP-for-numeric-and-categorical-data)\n",
    "3. [Create end of multi-imput model](#Create-final-layers-of-multi-input-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update pretrained CNN models\n",
    "\n",
    "Starting with ResNet50, but will do the others next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "baseModelResNet = ResNet50(weights=\"imagenet\", include_top=False,\n",
    "                           input_tensor=Input(shape=(32, 32, 3)))\n",
    "\n",
    "# baseModelIv3 = InceptionV3(weights=\"imagenet\", include_top=False,\n",
    "#                             input_tensor=Input(shape=(1,32, 32, 3)))\n",
    "\n",
    "# baseModelResIv2 = InceptionResNetV2(weights=\"imagenet\", include_top=False,\n",
    "#                                       input_tensor=Input(shape=(32, 32, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "chanDim = -1\n",
    "\n",
    "# flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "headModel = baseModelResNet.output\n",
    "headModel = Flatten()(headModel)\n",
    "headModel = Dense(16)(headModel)\n",
    "headModel = Activation(\"relu\")(headModel)\n",
    "headModel = BatchNormalization(axis=chanDim)(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "# apply another FC layer, this one to match the number of nodes\n",
    "# coming out of the MLP\n",
    "headModel = Dense(4)(headModel)\n",
    "headModel = Activation(\"relu\")(headModel)\n",
    "\n",
    "\n",
    "baseModelResNet.trainable = False\n",
    "\n",
    "cnn = Model(inputs=baseModelResNet.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # construct the head of the model that will be placed on top of the\n",
    "# # the base model\n",
    "# headModel = baseModel.output\n",
    "# headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "# headModel = Flatten(name=\"flatten\")(headModel)\n",
    "# headModel = Dense(256, activation=\"relu\")(headModel)\n",
    "# headModel = Dropout(0.5)(headModel)\n",
    "# headModel = Dense(len(config.CLASSES), activation=\"softmax\")(headModel)\n",
    "# # place the head FC model on top of the base model (this will become\n",
    "# # the actual model we will train)\n",
    "# model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "# # loop over all layers in the base model and freeze them so they will\n",
    "# # *not* be updated during the training process\n",
    "# for layer in baseModel.layers:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build MLP for numeric and categorical data\n",
    "\n",
    "We're going to start with something super basic initially to see how this does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress=False):\n",
    "    # define our MLP network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim=dim, activation=\"relu\"))\n",
    "    model.add(Dense(4, activation=\"relu\"))\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "        # return our model\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAttrX = model_data_dict['df_5_min']['X_train_p']\n",
    "mlp = create_mlp(trainAttrX.shape[1], regress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the final section of our model\n",
    "\n",
    "Fully connected and with linear activation function for regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the input to our final set of layers as the *output* of both\n",
    "# the MLP and CNN\n",
    "combinedInput = concatenate([mlp.output, cnn.output])\n",
    "\n",
    "# our final FC layer head will have two dense layers, the final one\n",
    "# being our regression head\n",
    "x = Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final layers of multi input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_paper",
   "language": "python",
   "name": "research_paper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
